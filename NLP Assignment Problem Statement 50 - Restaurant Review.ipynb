{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Group Members:\n",
    "    \n",
    " - Aiswarya S Parvathy\n",
    " - Vengadesh S\n",
    " - Nipun Gupta   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objective: \n",
    "\n",
    "Build a prediction model to predict whether a review on the restaurant is positive or negative."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the csv dataset as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev = pd.read_csv('RestaurantReview.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The selection on the menu was great and so were the prices.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                    Review  \\\n",
       "0  Wow... Loved this place.                                                                  \n",
       "1  Crust is not good.                                                                        \n",
       "2  Not tasty and the texture was just nasty.                                                 \n",
       "3  Stopped by during the late May bank holiday off Rick Steve recommendation and loved it.   \n",
       "4  The selection on the menu was great and so were the prices.                               \n",
       "\n",
       "   Liked  \n",
       "0  1      \n",
       "1  0      \n",
       "2  0      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking details of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 2 columns):\n",
      " Review    1000 non-null object\n",
      "Liked      1000 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 15.7+ KB\n"
     ]
    }
   ],
   "source": [
    "Rest_rev.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([' Review', 'Liked'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The column **Review** has a leading space in its name. So we can rename the column to remove this leading space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev = Rest_rev.rename(columns={' Review':'Review'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Review', 'Liked'], dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The leading space has been removed from the **Reivew** column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Liked\n",
       "count  1000.00000\n",
       "mean   0.50000   \n",
       "std    0.50025   \n",
       "min    0.00000   \n",
       "25%    0.00000   \n",
       "50%    0.50000   \n",
       "75%    1.00000   \n",
       "max    1.00000   "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output of the **describe()** functions shows only the numerical column and not the text column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for presence of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review    0\n",
       "Liked     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are no missing values in the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for presence of duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.duplicated(subset=None, keep='first').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 duplicate records in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the duplicate records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev = Rest_rev[Rest_rev.duplicated(Rest_rev.columns.tolist(), keep='first')==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.duplicated(subset=None, keep='first').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(996, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Duplicate records have been removed from the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleaning the punctuation marks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of punctuation marks to be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/', ':', ';', '<', '=', '>', '?', '@', '[', '\\\\', ']', '^', '_', '`', '{', '|', '}', '~']\n"
     ]
    }
   ],
   "source": [
    "print(list(string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    no_punct = \"\".join([c if c not in string.punctuation else \" \" for c in text])\n",
    "    return no_punct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev['Review'] = Rest_rev['Review'].apply(lambda x: remove_punctuation(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting all uppercase characters to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev['Review'] = Rest_rev['Review'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eliminating the numbers from the **Review** column as they do not contribute in predicting the sentiment of a review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev['Review'] = [re.sub('\\d+', '', e) for e in Rest_rev['Review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing unnecessary spaces from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev['Review'] = [re.sub('\\s+', ' ', e) for e in Rest_rev['Review']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing leading or trailing spaces from the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev['Review'] = Rest_rev['Review'].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nipun.gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev['Review'] = Rest_rev['Review'].apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wow, loved, this, place]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[crust, is, not, good]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[not, tasty, and, the, texture, was, just, nasty]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[stopped, by, during, the, late, may, bank, holiday, off, rick, steve, recommendation, and, loved, it]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[the, selection, on, the, menu, was, great, and, so, were, the, prices]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                   Review  \\\n",
       "0  [wow, loved, this, place]                                                                                \n",
       "1  [crust, is, not, good]                                                                                   \n",
       "2  [not, tasty, and, the, texture, was, just, nasty]                                                        \n",
       "3  [stopped, by, during, the, late, may, bank, holiday, off, rick, steve, recommendation, and, loved, it]   \n",
       "4  [the, selection, on, the, menu, was, great, and, so, were, the, prices]                                  \n",
       "\n",
       "   Liked  \n",
       "0  1      \n",
       "1  0      \n",
       "2  0      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The **Review** column has been tokenized i.e. split into tokens/pieces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing the stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nipun.gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the **English** language stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of english stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_english)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certain words in the above including **not**, **until**, **while**, **against** etc may contribute to the sentiment of a review. So they may need to be retained in the review and thus need to be removed from the above list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english_set = set(stopwords_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english_set = stopwords_english_set.difference({'until', 'while', 'against', 'between', 'during', 'before', 'after', 'above', 'below', 'not'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_english = list(stopwords_english_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['each', 'herself', 'i', 'they', 'then', 'me', 't', \"mightn't\", 'myself', 'because', 're', 'is', 'these', 'yourselves', \"won't\", 'this', 'hadn', 'did', 'doesn', 'mightn', 'yourself', 'who', 'o', 'where', 'how', 'here', 'he', 'them', 'into', 'of', 'were', \"haven't\", 'mustn', 'will', 'ours', 'himself', \"wasn't\", 'has', 'itself', 'down', 'do', 'doing', 'a', 'there', 'shouldn', 'most', 'about', 'than', \"hasn't\", 'no', \"shouldn't\", 'and', 'haven', 'ourselves', \"doesn't\", 'was', 'ma', 'own', 've', 'any', 'ain', 'those', \"mustn't\", 'with', 'as', 'off', 'needn', 'on', \"couldn't\", 'both', 'some', \"that'll\", 'hers', 'are', 'an', 'in', 'at', \"you'll\", 'am', 'what', 'very', 'have', 'we', 'themselves', 'be', 'so', 'but', 'isn', 'under', 'once', 'if', 'weren', 'few', \"you've\", 'just', 'such', 'which', 'your', 'now', 'from', 'by', 'd', 'whom', \"hadn't\", \"you're\", 'why', 'more', 'my', 'does', 'his', 'you', 'the', 'for', 'other', \"she's\", 'through', 'y', 'couldn', 'she', 'him', \"you'd\", \"don't\", 'wouldn', 'her', \"aren't\", 'to', 'its', 'having', 'when', 'too', 'all', 's', \"wouldn't\", \"needn't\", 'being', 'up', 'don', 'again', \"should've\", 'aren', 'or', 'nor', 'out', 'same', \"weren't\", \"it's\", 'won', \"didn't\", 'should', 'yours', 'had', 'll', 'wasn', 'm', 'our', 'been', \"shan't\", 'it', 'hasn', 'over', \"isn't\", 'theirs', 'that', 'shan', 'can', 'didn', 'further', 'their', 'only']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords_english)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):        \n",
    "    words = [w for w in text if w not in stopwords_english]\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev['Review'] = Rest_rev['Review'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wow, loved, place]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[crust, not, good]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[not, tasty, texture, nasty]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[stopped, during, late, may, bank, holiday, rick, steve, recommendation, loved]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[selection, menu, great, prices]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Review  \\\n",
       "0  [wow, loved, place]                                                               \n",
       "1  [crust, not, good]                                                                \n",
       "2  [not, tasty, texture, nasty]                                                      \n",
       "3  [stopped, during, late, may, bank, holiday, rick, steve, recommendation, loved]   \n",
       "4  [selection, menu, great, prices]                                                  \n",
       "\n",
       "   Liked  \n",
       "0  1      \n",
       "1  0      \n",
       "2  0      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The stopwords have been removed from the **Review** column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatization of Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lemmatization** shorten words back to their root form. **Lemmatizing** maps common words into one base. It returns a proper word that can be found in the dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To implement Lemmatization using NLTK, we require **wordnet** and **WordNetLemmatizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nipun.gupta\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_lemmatizer(text):\n",
    "    lem_text = [lemmatizer.lemmatize(i) for i in text]\n",
    "    return lem_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev['Review'] = Rest_rev['Review'].apply(lambda x: word_lemmatizer(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wow, loved, place]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[crust, not, good]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[not, tasty, texture, nasty]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[stopped, during, late, may, bank, holiday, rick, steve, recommendation, loved]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[selection, menu, great, price]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                            Review  \\\n",
       "0  [wow, loved, place]                                                               \n",
       "1  [crust, not, good]                                                                \n",
       "2  [not, tasty, texture, nasty]                                                      \n",
       "3  [stopped, during, late, may, bank, holiday, rick, steve, recommendation, loved]   \n",
       "4  [selection, menu, great, price]                                                   \n",
       "\n",
       "   Liked  \n",
       "0  1      \n",
       "1  0      \n",
       "2  0      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming the preprocessed Review to **cleaned_Review**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev = Rest_rev.rename(columns={'Review':'cleaned_Review'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[wow, loved, place]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[crust, not, good]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[not, tasty, texture, nasty]</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[stopped, during, late, may, bank, holiday, rick, steve, recommendation, loved]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[selection, menu, great, price]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    cleaned_Review  \\\n",
       "0  [wow, loved, place]                                                               \n",
       "1  [crust, not, good]                                                                \n",
       "2  [not, tasty, texture, nasty]                                                      \n",
       "3  [stopped, during, late, may, bank, holiday, rick, steve, recommendation, loved]   \n",
       "4  [selection, menu, great, price]                                                   \n",
       "\n",
       "   Liked  \n",
       "0  1      \n",
       "1  0      \n",
       "2  0      \n",
       "3  1      \n",
       "4  1      "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rest_rev.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rest_rev.to_csv('Rest_rev_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rest_rev = pd.read_csv('Rest_rev_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WorldCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the dataframe into train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
    "df_train, df_test = train_test_split(Rest_rev, test_size = 0.3, random_state = 42, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resetting the indices of the training and testing dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.reset_index(inplace = True, drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['disappointed', 'ordered', 'big', 'bay', 'pla...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['every', 'time', 'eat', 'see', 'caring', 'tea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['food', 'par', 'denny', 'say', 'not', 'good']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['interesting', 'part', 'town', 'place', 'amaz...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['not', 'good', 'stretch', 'imagination']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_Review  Liked\n",
       "0  ['disappointed', 'ordered', 'big', 'bay', 'pla...      0\n",
       "1  ['every', 'time', 'eat', 'see', 'caring', 'tea...      1\n",
       "2     ['food', 'par', 'denny', 'say', 'not', 'good']      0\n",
       "3  ['interesting', 'part', 'town', 'place', 'amaz...      1\n",
       "4          ['not', 'good', 'stretch', 'imagination']      0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cleaned_Review</th>\n",
       "      <th>Liked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['excellent']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>['server', 'suck', 'wait', 'correction', 'serv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['back']</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['hate', 'thing', 'much', 'cheap', 'quality', ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['think', 'going', 'back', 'anytime', 'soon']</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      cleaned_Review  Liked\n",
       "0                                      ['excellent']      1\n",
       "1  ['server', 'suck', 'wait', 'correction', 'serv...      0\n",
       "2                                           ['back']      1\n",
       "3  ['hate', 'thing', 'much', 'cheap', 'quality', ...      0\n",
       "4      ['think', 'going', 'back', 'anytime', 'soon']      0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The indices have been reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a TF-IDF object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an object for **TfidfVectorizer** to convert the text data into a numeric representation/vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multinomial classifiers are quite useful when working with text data. Since **Multinomial Naive Bayes** algorithm is  useful for discrete counts, we can use **MultinomialNB**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have set some parameters in the TfidfVectorizer. **max_df=0.15** means that only the words whose frequency of occurrence in the documents is a maximum of 0.15 will be considered whereas the words having frequency higher than 0.15 will not be considered as they will not matter much since they are commonly occurring in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer_tf = TfidfVectorizer(max_df=0.15, min_df=0, max_features=10000, use_idf=False,norm=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use **make_pipeline()** function to take the output of **TfidfVectorizer()** and push that to the **MultinomialNB()**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(vectorizer_tf, MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidfvectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.15, max_features=10000, min_df=0,\n",
       "        ngram_range=(1, 1), norm=None, preprocessor=None, smooth...   vocabulary=None)), ('multinomialnb', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(df_train.cleaned_Review, df_train.Liked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making predictions on the testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = model.predict(df_test.cleaned_Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting a **confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = confusion_matrix(df_test.Liked, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(91.68,0.5,'Predicted label')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(mat.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "plt.xlabel('True label')\n",
    "plt.ylabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following observations can be concluded about the performance:\n",
    "    \n",
    " - 128 is the number of true positives i.e. The number of actual negative reviews that were predicted negatively be the model\n",
    " - 109 is the number of true negatives i.e. The number of actual positive reviews that were predicted positively be the model\n",
    " - 27 is the number of false positives i.e. The number of actual negative reviews that were predicted positively be the model\n",
    " - 35 is the number of false negatives i.e. The number of actual positive reviews that were predicted negatively be the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
